{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a23fde-1583-4918-b78b-fb2fd0f81c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/home/lonya/doc/deeph/demo-CrI3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f26d6a3-57af-4d82-a339-5ffda2f7a2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e062981-9549-4990-ae56-0710c0673e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train config from: CrI3_monolayer.ini\n",
      "\n",
      "------- xDeepH model training begins -------\n",
      "Output will be stored under: ./results/monolayer_CrI3/2024-05-13_10-03-45\n",
      "Using random seed: 42\n",
      "Data type during training: torch.float32\n",
      "Saved xDeepH source code to output dir\n",
      "\n",
      "------- Preparation of training data -------\n",
      "\n",
      "Processing graph data...\n",
      "Graph data file: HGraph-CrI3_monolayer_RM_100x10-rFromDFT-edge=Aij.pkl\n",
      "Use existing graph data file\n",
      "Finish loading the processed 980 structures (spinful: True, the number of atomic types: 2), cost 6.56 seconds\n",
      "\n",
      "Automatically generated target and net_out_irreps. \n",
      "Details saved to: ./results/monolayer_CrI3/2024-05-13_10-03-45/targets.txt\n",
      "\n",
      "Setting mask for dataset...\n",
      "Finished setting mask for dataset, cost 49.45 seconds\n",
      "\n",
      "------- Data loader for training -------\n",
      "size of train set: 588\n",
      "size of val set: 196\n",
      "size of test set: 196\n",
      "Batch size: 1\n",
      "\n",
      "------- Build model -------\n",
      "Building model...\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/jit/_check.py:177: UserWarning: The TorchScript type system doesn't support instance-level annotations on empty non-base types in `__init__`. Instead, either 1) use a type annotation in the class body, or 2) wrap the type in `torch.jit.Attribute`.\n",
      "  warnings.warn(\n",
      "Finished building model, cost 14.40 seconds.\n",
      "The model you built has 2126632 parameters.\n",
      "Output constructer associated to net.\n",
      "\n",
      "===== xDeepH model structure: =====\n",
      "using spherical harmonics: 1x0e+1x1o+1x2e+1x3o+1x4e\n",
      "=== layer 0 ===\n",
      "node update: (64x0e -> 64x0e+32x1o+16x2e+8x3o+8x4e)\n",
      "edge update: (64x0e -> 64x0e+32x1o+16x1e+16x2e+8x3o+8x4e)\n",
      "=== layer 1 ===\n",
      "node update: (64x0e+32x1o+16x2e+8x3o+8x4e -> 64x0e+32x1o+16x1e+16x2e+8x3o+8x4e)\n",
      "edge update: (64x0e+32x1o+16x1e+16x2e+8x3o+8x4e -> 64x0e+32x1o+16x1e+16x2e+8x3o+8x4e)\n",
      "=== layer 2 ===\n",
      "node update: (64x0e+32x1o+16x1e+16x2e+8x3o+8x4e -> 64x0e+32x1o+16x1e+16x2e+8x3o+8x4e)\n",
      "edge update: (64x0e+32x1o+16x1e+16x2e+8x3o+8x4e -> 64x0e+32x1o+16x1e+16x2e+8x3o+8x4e)\n",
      "=== previous local magnetic layer ===\n",
      "edge update: (16x0e+16x0e+64x0e+32x1o+16x1e+16x2e+8x3o+8x4e -> 64x0e+32x1o+16x1e+16x2e+8x3o+8x4e)\n",
      "spherical harmonics for position vector and magnetic moment: 1x0eE+1x1oE+1x2eE+1x3oE+1x4eE+1x0eE+1x1eO+1x2eE+1x3eO+1x4eE+1x0eE+1x1eO+1x2eE+1x3eO+1x4eE\n",
      "neighbor aggregation: 8x0eE+8x1oE+8x1eO+8x2eE+8x3oE+8x3eO+8x4eE\n",
      "=== local magnetic layer 0 ===\n",
      "local magnetic: (64x0eE+32x1oE+16x1eE+16x2eE+8x3oE+8x4eE -> 64x0eE+64x0eO+32x1oE+16x1eE+16x2eE+8x3oE+8x4eE+32x1oO+16x1eO+16x2eO+8x3oO+8x4eO)\n",
      "=== local magnetic layer 1 ===\n",
      "local magnetic: (64x0eE+64x0eO+32x1oE+16x1eE+16x2eE+8x3oE+8x4eE+32x1oO+16x1eO+16x2eO+8x3oO+8x4eO -> 64x0eE+64x0eO+32x1oE+16x1eE+16x2eE+8x3oE+8x4eE+32x1oO+16x1eO+16x2eO+8x3oO+8x4eO)\n",
      "=== local magnetic layer 2 ===\n",
      "local magnetic: (64x0eE+64x0eO+32x1oE+16x1eE+16x2eE+8x3oE+8x4eE+32x1oO+16x1eO+16x2eO+8x3oO+8x4eO -> 20x0oE+25x0eE+20x0oO+25x0eO+48x1oE+53x1eE+44x2oE+52x2eE+24x3oE+32x3eE+8x4oE+12x4eE+4x5eE+48x1oO+53x1eO+44x2oO+52x2eO+24x3oO+32x3eO+8x4oO+12x4eO+4x5eO)\n",
      "=== output ===\n",
      "output node: (1x0e)\n",
      "output edge: (1x0eE+1x1eO+1x0eE+1x1eO+1x0eE+1x1eO+1x1oE+1x0oO+1x1oO+1x2oO+1x1oE+1x0oO+1x1oO+1x2oO+1x2eE+1x1eO+1x2eO+1x3eO+1x0eE+1x1eO+1x0eE+1x1eO+1x0eE+1x1eO+1x1oE+1x0oO+1x1oO+1x2oO+1x1oE+1x0oO+1x1oO+1x2oO+1x2eE+1x1eO+1x2eO+1x3eO+1x0eE+1x1eO+1x0eE+1x1eO+1x0eE+1x1eO+1x1oE+1x0oO+1x1oO+1x2oO+1x1oE+1x0oO+1x1oO+1x2oO+1x2eE+1x1eO+1x2eO+1x3eO+1x1oE+1x0oO+1x1oO+1x2oO+1x1oE+1x0oO+1x1oO+1x2oO+1x1oE+1x0oO+1x1oO+1x2oO+1x0eE+1x1eE+1x2eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x0eE+1x1eE+1x2eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x1oE+1x0oO+1x1oO+1x2oO+1x1oE+1x0oO+1x1oO+1x2oO+1x1oE+1x0oO+1x1oO+1x2oO+1x0eE+1x1eE+1x2eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x0eE+1x1eE+1x2eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x2eE+1x1eO+1x2eO+1x3eO+1x2eE+1x1eO+1x2eO+1x3eO+1x2eE+1x1eO+1x2eO+1x3eO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x0eE+1x1eE+1x2eE+1x3eE+1x4eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x2eO+1x3eO+1x4eO+1x3eO+1x4eO+1x5eO+1x2eE+1x1eO+1x2eO+1x3eO+1x2eE+1x1eO+1x2eO+1x3eO+1x2eE+1x1eO+1x2eO+1x3eO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x0eE+1x1eE+1x2eE+1x3eE+1x4eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x2eO+1x3eO+1x4eO+1x3eO+1x4eO+1x5eO+1x2eE+1x1eO+1x2eO+1x3eO+1x2eE+1x1eO+1x2eO+1x3eO+1x2eE+1x1eO+1x2eO+1x3eO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x1oE+1x2oE+1x3oE+1x0oO+1x1oO+1x2oO+1x1oO+1x2oO+1x3oO+1x2oO+1x3oO+1x4oO+1x0eE+1x1eE+1x2eE+1x3eE+1x4eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x2eO+1x3eO+1x4eO+1x3eO+1x4eO+1x5eO+1x0eE+1x1eE+1x2eE+1x3eE+1x4eE+1x1eO+1x0eO+1x1eO+1x2eO+1x1eO+1x2eO+1x3eO+1x2eO+1x3eO+1x4eO+1x3eO+1x4eO+1x5eO+1x0eO+1x1eE+1x0eO+1x1eE+1x0eO+1x1eE+1x1oO+1x0oE+1x1oE+1x2oE+1x1oO+1x0oE+1x1oE+1x2oE+1x2eO+1x1eE+1x2eE+1x3eE+1x0eO+1x1eE+1x0eO+1x1eE+1x0eO+1x1eE+1x1oO+1x0oE+1x1oE+1x2oE+1x1oO+1x0oE+1x1oE+1x2oE+1x2eO+1x1eE+1x2eE+1x3eE+1x0eO+1x1eE+1x0eO+1x1eE+1x0eO+1x1eE+1x1oO+1x0oE+1x1oE+1x2oE+1x1oO+1x0oE+1x1oE+1x2oE+1x2eO+1x1eE+1x2eE+1x3eE+1x1oO+1x0oE+1x1oE+1x2oE+1x1oO+1x0oE+1x1oE+1x2oE+1x1oO+1x0oE+1x1oE+1x2oE+1x0eO+1x1eO+1x2eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x0eO+1x1eO+1x2eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x1oO+1x0oE+1x1oE+1x2oE+1x1oO+1x0oE+1x1oE+1x2oE+1x1oO+1x0oE+1x1oE+1x2oE+1x0eO+1x1eO+1x2eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x0eO+1x1eO+1x2eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x2eO+1x1eE+1x2eE+1x3eE+1x2eO+1x1eE+1x2eE+1x3eE+1x2eO+1x1eE+1x2eE+1x3eE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x0eO+1x1eO+1x2eO+1x3eO+1x4eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x2eE+1x3eE+1x4eE+1x3eE+1x4eE+1x5eE+1x2eO+1x1eE+1x2eE+1x3eE+1x2eO+1x1eE+1x2eE+1x3eE+1x2eO+1x1eE+1x2eE+1x3eE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x0eO+1x1eO+1x2eO+1x3eO+1x4eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x2eE+1x3eE+1x4eE+1x3eE+1x4eE+1x5eE+1x2eO+1x1eE+1x2eE+1x3eE+1x2eO+1x1eE+1x2eE+1x3eE+1x2eO+1x1eE+1x2eE+1x3eE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x1oO+1x2oO+1x3oO+1x0oE+1x1oE+1x2oE+1x1oE+1x2oE+1x3oE+1x2oE+1x3oE+1x4oE+1x0eO+1x1eO+1x2eO+1x3eO+1x4eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x2eE+1x3eE+1x4eE+1x3eE+1x4eE+1x5eE+1x0eO+1x1eO+1x2eO+1x3eO+1x4eO+1x1eE+1x0eE+1x1eE+1x2eE+1x1eE+1x2eE+1x3eE+1x2eE+1x3eE+1x4eE+1x3eE+1x4eE+1x5eE)\n",
      "\n",
      "------- Preparation for training -------\n",
      "Using optimizer Adam with initial lr=0.002, betas=(0.9, 0.999)\n",
      "Loss type: MSE over all matrix elements\n",
      "Tensorboard recorder initialized\n",
      "/root/miniconda3/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n",
      "Using pytorch scheduler ReduceLROnPlateau\n",
      "Starting new training process\n",
      "\n",
      "------- Begin training -------\n",
      "====================\n",
      "Epoch #0      | Time: 00d 00h 10m  | LR: 2.00e-03  | Epoch time: 622.52  | Train loss: 5.01e-02  | Val loss: 1.35e-03\n",
      "Target 007 has maximum loss 7.85e-03; Target 023 has minimum loss 6.17e-04\n",
      "====================\n",
      "Epoch #1      | Time: 00d 00h 20m  | LR: 2.00e-03  | Epoch time: 576.72  | Train loss: 9.09e-04  | Val loss: 6.30e-04\n",
      "Target 007 has maximum loss 3.11e-03; Target 023 has minimum loss 2.34e-04\n",
      "====================\n",
      "Epoch #2      | Time: 00d 00h 29m  | LR: 2.00e-03  | Epoch time: 574.00  | Train loss: 5.06e-04  | Val loss: 4.01e-04\n",
      "Target 007 has maximum loss 1.86e-03; Target 023 has minimum loss 1.37e-04\n",
      "====================\n",
      "Epoch #3      | Time: 00d 00h 39m  | LR: 2.00e-03  | Epoch time: 575.41  | Train loss: 3.55e-04  | Val loss: 3.55e-04\n",
      "Target 007 has maximum loss 1.44e-03; Target 023 has minimum loss 1.13e-04\n",
      "====================\n",
      "Epoch #4      | Time: 00d 00h 48m  | LR: 2.00e-03  | Epoch time: 580.32  | Train loss: 2.79e-04  | Val loss: 2.87e-04\n",
      "Target 014 has maximum loss 1.34e-03; Target 023 has minimum loss 8.69e-05\n",
      "====================\n",
      "Epoch #5      | Time: 00d 00h 58m  | LR: 2.00e-03  | Epoch time: 578.36  | Train loss: 2.31e-04  | Val loss: 2.07e-04\n",
      "Target 007 has maximum loss 8.56e-04; Target 033 has minimum loss 6.20e-05\n",
      "====================\n",
      "Epoch #6      | Time: 00d 01h 08m  | LR: 2.00e-03  | Epoch time: 580.61  | Train loss: 1.90e-04  | Val loss: 1.57e-04\n",
      "Target 014 has maximum loss 6.73e-04; Target 033 has minimum loss 4.70e-05\n",
      "====================\n",
      "Epoch #7      | Time: 00d 01h 17m  | LR: 2.00e-03  | Epoch time: 576.16  | Train loss: 1.53e-04  | Val loss: 1.58e-04\n",
      "Target 007 has maximum loss 9.56e-04; Target 033 has minimum loss 3.95e-05\n",
      "====================\n",
      "Epoch #8      | Time: 00d 01h 27m  | LR: 2.00e-03  | Epoch time: 573.34  | Train loss: 1.42e-04  | Val loss: 1.36e-04\n",
      "Target 014 has maximum loss 5.56e-04; Target 023 has minimum loss 3.55e-05\n",
      "====================\n",
      "Epoch #9      | Time: 00d 01h 36m  | LR: 2.00e-03  | Epoch time: 573.66  | Train loss: 1.22e-04  | Val loss: 1.06e-04\n",
      "Target 000 has maximum loss 4.71e-04; Target 033 has minimum loss 2.86e-05\n",
      "====================\n",
      "Epoch #10     | Time: 00d 01h 46m  | LR: 2.00e-03  | Epoch time: 573.56  | Train loss: 1.13e-04  | Val loss: 9.91e-05\n",
      "Target 014 has maximum loss 4.51e-04; Target 018 has minimum loss 2.70e-05\n",
      "====================\n",
      "Epoch #11     | Time: 00d 01h 56m  | LR: 2.00e-03  | Epoch time: 573.79  | Train loss: 1.00e-04  | Val loss: 1.36e-04\n",
      "Target 014 has maximum loss 1.20e-03; Target 003 has minimum loss 3.50e-05\n",
      "====================\n",
      "Epoch #12     | Time: 00d 02h 05m  | LR: 2.00e-03  | Epoch time: 573.70  | Train loss: 9.57e-05  | Val loss: 7.73e-05\n",
      "Target 014 has maximum loss 2.99e-04; Target 023 has minimum loss 1.98e-05\n",
      "====================\n",
      "Epoch #13     | Time: 00d 02h 15m  | LR: 2.00e-03  | Epoch time: 574.76  | Train loss: 8.53e-05  | Val loss: 7.07e-05\n",
      "Target 014 has maximum loss 2.18e-04; Target 018 has minimum loss 1.55e-05\n",
      "====================\n",
      "Epoch #14     | Time: 00d 02h 24m  | LR: 2.00e-03  | Epoch time: 574.01  | Train loss: 8.18e-05  | Val loss: 7.60e-05\n",
      "Target 001 has maximum loss 3.46e-04; Target 018 has minimum loss 1.86e-05\n",
      "====================\n",
      "Epoch #15     | Time: 00d 02h 34m  | LR: 2.00e-03  | Epoch time: 572.53  | Train loss: 8.28e-05  | Val loss: 6.07e-05\n",
      "Target 014 has maximum loss 1.84e-04; Target 018 has minimum loss 1.18e-05\n",
      "====================\n",
      "Epoch #16     | Time: 00d 02h 43m  | LR: 2.00e-03  | Epoch time: 573.38  | Train loss: 7.04e-05  | Val loss: 7.26e-05\n",
      "Target 007 has maximum loss 3.49e-04; Target 018 has minimum loss 1.32e-05\n",
      "====================\n",
      "Epoch #17     | Time: 00d 02h 53m  | LR: 2.00e-03  | Epoch time: 572.38  | Train loss: 7.59e-05  | Val loss: 7.52e-05\n",
      "Target 025 has maximum loss 2.13e-04; Target 003 has minimum loss 1.10e-05\n",
      "====================\n",
      "Epoch #18     | Time: 00d 03h 03m  | LR: 2.00e-03  | Epoch time: 572.68  | Train loss: 6.82e-05  | Val loss: 5.85e-05\n",
      "Target 000 has maximum loss 2.34e-04; Target 018 has minimum loss 9.15e-06\n",
      "====================\n",
      "Epoch #19     | Time: 00d 03h 12m  | LR: 2.00e-03  | Epoch time: 573.08  | Train loss: 6.37e-05  | Val loss: 6.71e-05\n",
      "Target 000 has maximum loss 3.21e-04; Target 018 has minimum loss 1.12e-05\n",
      "====================\n",
      "Epoch #20     | Time: 00d 03h 22m  | LR: 2.00e-03  | Epoch time: 573.84  | Train loss: 6.30e-05  | Val loss: 6.85e-05\n",
      "Target 014 has maximum loss 4.49e-04; Target 023 has minimum loss 1.84e-05\n",
      "====================\n",
      "Epoch #21     | Time: 00d 03h 31m  | LR: 2.00e-03  | Epoch time: 572.84  | Train loss: 6.13e-05  | Val loss: 5.29e-05\n",
      "Target 014 has maximum loss 1.60e-04; Target 003 has minimum loss 6.60e-06\n",
      "====================\n",
      "Epoch #22     | Time: 00d 03h 41m  | LR: 2.00e-03  | Epoch time: 573.09  | Train loss: 6.05e-05  | Val loss: 5.22e-05\n",
      "Target 010 has maximum loss 1.49e-04; Target 018 has minimum loss 6.39e-06\n",
      "====================\n",
      "Epoch #23     | Time: 00d 03h 50m  | LR: 2.00e-03  | Epoch time: 573.49  | Train loss: 5.96e-05  | Val loss: 4.85e-05\n",
      "Target 000 has maximum loss 1.83e-04; Target 003 has minimum loss 7.03e-06\n",
      "====================\n",
      "Epoch #24     | Time: 00d 04h 00m  | LR: 2.00e-03  | Epoch time: 573.78  | Train loss: 5.40e-05  | Val loss: 4.67e-05\n",
      "Target 025 has maximum loss 1.23e-04; Target 018 has minimum loss 5.60e-06\n",
      "====================\n",
      "Epoch #25     | Time: 00d 04h 10m  | LR: 2.00e-03  | Epoch time: 573.95  | Train loss: 5.48e-05  | Val loss: 4.68e-05\n",
      "Target 014 has maximum loss 1.65e-04; Target 018 has minimum loss 8.87e-06\n",
      "====================\n",
      "Epoch #26     | Time: 00d 04h 19m  | LR: 2.00e-03  | Epoch time: 573.92  | Train loss: 4.83e-05  | Val loss: 5.23e-05\n",
      "Target 036 has maximum loss 1.43e-04; Target 018 has minimum loss 8.13e-06\n",
      "====================\n",
      "Epoch #27     | Time: 00d 04h 29m  | LR: 2.00e-03  | Epoch time: 573.95  | Train loss: 4.56e-05  | Val loss: 3.63e-05\n",
      "Target 007 has maximum loss 1.19e-04; Target 018 has minimum loss 7.18e-06\n",
      "====================\n",
      "Epoch #28     | Time: 00d 04h 38m  | LR: 2.00e-03  | Epoch time: 573.68  | Train loss: 4.25e-05  | Val loss: 4.51e-05\n",
      "Target 001 has maximum loss 2.53e-04; Target 003 has minimum loss 7.77e-06\n",
      "====================\n",
      "Epoch #29     | Time: 00d 04h 48m  | LR: 2.00e-03  | Epoch time: 572.80  | Train loss: 3.89e-05  | Val loss: 3.73e-05\n",
      "Target 007 has maximum loss 1.79e-04; Target 018 has minimum loss 7.84e-06\n",
      "====================\n",
      "Epoch #30     | Time: 00d 04h 57m  | LR: 2.00e-03  | Epoch time: 572.52  | Train loss: 3.57e-05  | Val loss: 2.85e-05\n",
      "Target 000 has maximum loss 2.92e-04; Target 018 has minimum loss 5.48e-06\n",
      "====================\n",
      "Epoch #31     | Time: 00d 05h 07m  | LR: 2.00e-03  | Epoch time: 572.90  | Train loss: 3.05e-05  | Val loss: 2.48e-05\n",
      "Target 024 has maximum loss 7.57e-05; Target 023 has minimum loss 7.25e-06\n",
      "====================\n",
      "Epoch #32     | Time: 00d 05h 16m  | LR: 2.00e-03  | Epoch time: 572.76  | Train loss: 2.78e-05  | Val loss: 2.34e-05\n",
      "Target 036 has maximum loss 8.12e-05; Target 003 has minimum loss 6.46e-06\n",
      "====================\n",
      "Epoch #33     | Time: 00d 05h 26m  | LR: 2.00e-03  | Epoch time: 573.08  | Train loss: 2.45e-05  | Val loss: 2.62e-05\n",
      "Target 036 has maximum loss 1.66e-04; Target 003 has minimum loss 7.43e-06\n",
      "====================\n",
      "Epoch #34     | Time: 00d 05h 36m  | LR: 2.00e-03  | Epoch time: 573.64  | Train loss: 2.62e-05  | Val loss: 1.83e-05\n",
      "Target 000 has maximum loss 7.90e-05; Target 033 has minimum loss 4.92e-06\n",
      "====================\n",
      "Epoch #35     | Time: 00d 05h 45m  | LR: 2.00e-03  | Epoch time: 574.31  | Train loss: 2.14e-05  | Val loss: 1.56e-05\n",
      "Target 000 has maximum loss 1.18e-04; Target 003 has minimum loss 4.01e-06\n",
      "====================\n",
      "Epoch #36     | Time: 00d 05h 55m  | LR: 2.00e-03  | Epoch time: 573.70  | Train loss: 2.02e-05  | Val loss: 1.98e-05\n",
      "Target 006 has maximum loss 1.72e-04; Target 033 has minimum loss 5.58e-06\n",
      "====================\n",
      "Epoch #37     | Time: 00d 06h 04m  | LR: 2.00e-03  | Epoch time: 573.90  | Train loss: 2.10e-05  | Val loss: 2.72e-05\n",
      "Target 014 has maximum loss 2.45e-04; Target 023 has minimum loss 5.91e-06\n",
      "====================\n",
      "Epoch #38     | Time: 00d 06h 14m  | LR: 2.00e-03  | Epoch time: 574.69  | Train loss: 2.23e-05  | Val loss: 1.38e-05\n",
      "Target 000 has maximum loss 1.40e-04; Target 003 has minimum loss 3.85e-06\n",
      "====================\n",
      "Epoch #39     | Time: 00d 06h 24m  | LR: 2.00e-03  | Epoch time: 574.38  | Train loss: 1.83e-05  | Val loss: 1.36e-05\n",
      "Target 014 has maximum loss 5.75e-05; Target 023 has minimum loss 3.36e-06\n",
      "====================\n",
      "Epoch #40     | Time: 00d 06h 33m  | LR: 2.00e-03  | Epoch time: 574.68  | Train loss: 1.81e-05  | Val loss: 2.92e-05\n",
      "Target 001 has maximum loss 1.62e-04; Target 033 has minimum loss 8.26e-06\n",
      "====================\n",
      "Epoch #41     | Time: 00d 06h 43m  | LR: 2.00e-03  | Epoch time: 574.10  | Train loss: 1.84e-05  | Val loss: 1.42e-05\n",
      "Target 000 has maximum loss 1.33e-04; Target 018 has minimum loss 3.74e-06\n",
      "====================\n",
      "Epoch #42     | Time: 00d 06h 52m  | LR: 2.00e-03  | Epoch time: 575.14  | Train loss: 1.71e-05  | Val loss: 1.36e-05\n",
      "Target 014 has maximum loss 7.91e-05; Target 023 has minimum loss 3.80e-06\n",
      "====================\n",
      "Epoch #43     | Time: 00d 07h 02m  | LR: 2.00e-03  | Epoch time: 575.16  | Train loss: 1.80e-05  | Val loss: 1.45e-05\n",
      "Target 036 has maximum loss 1.40e-04; Target 003 has minimum loss 4.33e-06\n",
      "====================\n",
      "Epoch #44     | Time: 00d 07h 11m  | LR: 2.00e-03  | Epoch time: 574.56  | Train loss: 1.54e-05  | Val loss: 2.23e-05\n",
      "Target 004 has maximum loss 3.03e-04; Target 023 has minimum loss 6.03e-06\n",
      "====================\n",
      "Epoch #45     | Time: 00d 07h 21m  | LR: 2.00e-03  | Epoch time: 574.47  | Train loss: 1.52e-05  | Val loss: 1.09e-05\n",
      "Target 007 has maximum loss 4.90e-05; Target 018 has minimum loss 3.17e-06\n",
      "====================\n",
      "Epoch #46     | Time: 00d 07h 31m  | LR: 2.00e-03  | Epoch time: 574.67  | Train loss: 1.51e-05  | Val loss: 1.24e-05\n",
      "Target 004 has maximum loss 8.39e-05; Target 023 has minimum loss 3.06e-06\n",
      "====================\n",
      "Epoch #47     | Time: 00d 07h 40m  | LR: 2.00e-03  | Epoch time: 574.79  | Train loss: 1.57e-04  | Val loss: 2.55e-05\n",
      "Target 014 has maximum loss 9.84e-05; Target 018 has minimum loss 7.93e-06\n",
      "====================\n",
      "Epoch #48     | Time: 00d 07h 50m  | LR: 2.00e-03  | Epoch time: 574.16  | Train loss: 1.86e-05  | Val loss: 1.22e-05\n",
      "Target 014 has maximum loss 8.24e-05; Target 023 has minimum loss 4.05e-06\n",
      "====================\n",
      "Epoch #49     | Time: 00d 07h 59m  | LR: 2.00e-03  | Epoch time: 574.29  | Train loss: 1.41e-05  | Val loss: 1.44e-05\n",
      "Target 048 has maximum loss 3.79e-05; Target 018 has minimum loss 4.32e-06\n",
      "====================\n",
      "Epoch #50     | Time: 00d 08h 09m  | LR: 2.00e-03  | Epoch time: 573.81  | Train loss: 1.39e-05  | Val loss: 1.16e-05\n",
      "Target 014 has maximum loss 4.53e-05; Target 033 has minimum loss 3.64e-06\n",
      "====================\n",
      "Epoch #51     | Time: 00d 08h 19m  | LR: 2.00e-03  | Epoch time: 574.20  | Train loss: 1.40e-05  | Val loss: 1.21e-05\n",
      "Target 014 has maximum loss 9.96e-05; Target 033 has minimum loss 2.96e-06\n",
      "====================\n",
      "Epoch #52     | Time: 00d 08h 28m  | LR: 2.00e-03  | Epoch time: 574.25  | Train loss: 1.30e-05  | Val loss: 1.99e-05\n",
      "Target 000 has maximum loss 7.49e-05; Target 018 has minimum loss 3.67e-06\n",
      "====================\n",
      "Epoch #53     | Time: 00d 08h 38m  | LR: 2.00e-03  | Epoch time: 578.23  | Train loss: 1.57e-05  | Val loss: 1.03e-05\n",
      "Target 014 has maximum loss 5.37e-05; Target 023 has minimum loss 2.93e-06\n",
      "====================\n",
      "Epoch #54     | Time: 00d 08h 47m  | LR: 2.00e-03  | Epoch time: 574.84  | Train loss: 1.44e-05  | Val loss: 2.83e-05\n",
      "Target 042 has maximum loss 3.51e-04; Target 033 has minimum loss 5.95e-06\n",
      "====================\n",
      "Epoch #55     | Time: 00d 08h 57m  | LR: 2.00e-03  | Epoch time: 574.92  | Train loss: 1.22e-05  | Val loss: 8.65e-06\n",
      "Target 014 has maximum loss 4.45e-05; Target 003 has minimum loss 3.19e-06\n",
      "====================\n",
      "Epoch #56     | Time: 00d 09h 07m  | LR: 2.00e-03  | Epoch time: 573.32  | Train loss: 1.36e-05  | Val loss: 1.42e-05\n",
      "Target 024 has maximum loss 5.67e-05; Target 033 has minimum loss 4.47e-06\n",
      "====================\n",
      "Epoch #57     | Time: 00d 09h 16m  | LR: 2.00e-03  | Epoch time: 593.84  | Train loss: 1.19e-05  | Val loss: 1.15e-05\n",
      "Target 014 has maximum loss 1.21e-04; Target 003 has minimum loss 2.78e-06\n",
      "====================\n",
      "Epoch #58     | Time: 00d 09h 26m  | LR: 2.00e-03  | Epoch time: 601.18  | Train loss: 1.19e-05  | Val loss: 1.37e-05\n",
      "Target 014 has maximum loss 6.80e-05; Target 003 has minimum loss 3.84e-06\n",
      "====================\n",
      "Epoch #59     | Time: 00d 09h 37m  | LR: 2.00e-03  | Epoch time: 611.70  | Train loss: 1.35e-05  | Val loss: 9.43e-06\n",
      "Target 042 has maximum loss 5.29e-05; Target 033 has minimum loss 2.50e-06\n",
      "====================\n",
      "Epoch #60     | Time: 00d 09h 47m  | LR: 2.00e-03  | Epoch time: 602.62  | Train loss: 1.24e-05  | Val loss: 7.99e-06\n",
      "Target 000 has maximum loss 4.59e-05; Target 023 has minimum loss 2.33e-06\n",
      "====================\n",
      "Epoch #61     | Time: 00d 09h 57m  | LR: 2.00e-03  | Epoch time: 608.46  | Train loss: 1.13e-05  | Val loss: 2.79e-05\n",
      "Target 036 has maximum loss 2.51e-04; Target 015 has minimum loss 6.94e-06\n",
      "====================\n",
      "Epoch #62     | Time: 00d 10h 07m  | LR: 2.00e-03  | Epoch time: 611.75  | Train loss: 1.10e-05  | Val loss: 7.66e-06\n",
      "Target 001 has maximum loss 4.06e-05; Target 033 has minimum loss 2.25e-06\n",
      "====================\n",
      "Epoch #63     | Time: 00d 10h 17m  | LR: 2.00e-03  | Epoch time: 611.89  | Train loss: 1.04e-05  | Val loss: 1.02e-05\n",
      "Target 007 has maximum loss 1.70e-04; Target 033 has minimum loss 2.06e-06\n",
      "====================\n",
      "Epoch #64     | Time: 00d 10h 27m  | LR: 2.00e-03  | Epoch time: 610.11  | Train loss: 1.15e-05  | Val loss: 7.43e-06\n",
      "Target 000 has maximum loss 6.49e-05; Target 033 has minimum loss 2.01e-06\n",
      "====================\n",
      "Epoch #65     | Time: 00d 10h 38m  | LR: 2.00e-03  | Epoch time: 606.95  | Train loss: 1.09e-05  | Val loss: 1.21e-05\n",
      "Target 042 has maximum loss 7.28e-05; Target 033 has minimum loss 3.32e-06\n",
      "====================\n",
      "Epoch #66     | Time: 00d 10h 47m  | LR: 2.00e-03  | Epoch time: 585.07  | Train loss: 9.25e-06  | Val loss: 1.13e-05\n",
      "Target 042 has maximum loss 1.03e-04; Target 033 has minimum loss 2.73e-06\n",
      "====================\n",
      "Epoch #67     | Time: 00d 10h 57m  | LR: 2.00e-03  | Epoch time: 583.62  | Train loss: 1.03e-05  | Val loss: 7.40e-06\n",
      "Target 001 has maximum loss 2.01e-05; Target 003 has minimum loss 2.12e-06\n",
      "====================\n",
      "Epoch #68     | Time: 00d 11h 07m  | LR: 2.00e-03  | Epoch time: 582.30  | Train loss: 9.50e-06  | Val loss: 5.70e-06\n",
      "Target 006 has maximum loss 4.80e-05; Target 033 has minimum loss 1.70e-06\n",
      "====================\n",
      "Epoch #69     | Time: 00d 11h 17m  | LR: 2.00e-03  | Epoch time: 583.60  | Train loss: 1.20e-05  | Val loss: 8.50e-06\n",
      "Target 001 has maximum loss 3.81e-05; Target 033 has minimum loss 2.20e-06\n",
      "====================\n",
      "Epoch #70     | Time: 00d 11h 26m  | LR: 2.00e-03  | Epoch time: 581.27  | Train loss: 9.07e-06  | Val loss: 1.30e-05\n",
      "Target 036 has maximum loss 5.91e-05; Target 018 has minimum loss 3.06e-06\n",
      "====================\n",
      "Epoch #71     | Time: 00d 11h 36m  | LR: 2.00e-03  | Epoch time: 585.11  | Train loss: 1.03e-05  | Val loss: 6.36e-06\n",
      "Target 014 has maximum loss 2.54e-05; Target 003 has minimum loss 1.70e-06\n",
      "====================\n",
      "Epoch #72     | Time: 00d 11h 46m  | LR: 2.00e-03  | Epoch time: 580.97  | Train loss: 8.85e-06  | Val loss: 7.45e-06\n",
      "Target 004 has maximum loss 5.67e-05; Target 033 has minimum loss 1.81e-06\n",
      "====================\n",
      "Epoch #73     | Time: 00d 11h 55m  | LR: 2.00e-03  | Epoch time: 581.12  | Train loss: 1.20e-05  | Val loss: 1.03e-05\n",
      "Target 014 has maximum loss 1.24e-04; Target 003 has minimum loss 2.03e-06\n",
      "====================\n",
      "Epoch #74     | Time: 00d 12h 05m  | LR: 2.00e-03  | Epoch time: 576.09  | Train loss: 8.59e-06  | Val loss: 6.21e-06\n",
      "Target 001 has maximum loss 4.09e-05; Target 003 has minimum loss 1.43e-06\n",
      "====================\n",
      "Epoch #75     | Time: 00d 12h 15m  | LR: 2.00e-03  | Epoch time: 576.54  | Train loss: 1.01e-05  | Val loss: 5.66e-06\n",
      "Target 014 has maximum loss 2.54e-05; Target 033 has minimum loss 1.69e-06\n",
      "====================\n",
      "Epoch #76     | Time: 00d 12h 24m  | LR: 2.00e-03  | Epoch time: 576.74  | Train loss: 8.47e-06  | Val loss: 5.48e-06\n",
      "Target 024 has maximum loss 2.47e-05; Target 003 has minimum loss 1.83e-06\n",
      "====================\n",
      "Epoch #77     | Time: 00d 12h 34m  | LR: 2.00e-03  | Epoch time: 575.02  | Train loss: 7.94e-06  | Val loss: 1.42e-05\n",
      "Target 004 has maximum loss 1.27e-04; Target 035 has minimum loss 5.19e-06\n",
      "====================\n",
      "Epoch #78     | Time: 00d 12h 43m  | LR: 2.00e-03  | Epoch time: 577.04  | Train loss: 1.02e-05  | Val loss: 1.30e-05\n",
      "Target 006 has maximum loss 9.54e-05; Target 033 has minimum loss 3.69e-06\n",
      "====================\n",
      "Epoch #79     | Time: 00d 12h 53m  | LR: 2.00e-03  | Epoch time: 580.12  | Train loss: 8.14e-06  | Val loss: 5.05e-06\n",
      "Target 006 has maximum loss 2.70e-05; Target 023 has minimum loss 1.38e-06\n",
      "====================\n",
      "Epoch #80     | Time: 00d 13h 03m  | LR: 2.00e-03  | Epoch time: 582.16  | Train loss: 7.59e-06  | Val loss: 6.73e-06\n",
      "Target 006 has maximum loss 9.54e-05; Target 003 has minimum loss 1.70e-06\n",
      "====================\n",
      "Epoch #81     | Time: 00d 13h 13m  | LR: 2.00e-03  | Epoch time: 583.50  | Train loss: 1.01e-05  | Val loss: 4.89e-06\n",
      "Target 000 has maximum loss 2.55e-05; Target 003 has minimum loss 1.38e-06\n",
      "====================\n",
      "Epoch #82     | Time: 00d 13h 22m  | LR: 2.00e-03  | Epoch time: 593.22  | Train loss: 6.64e-06  | Val loss: 8.44e-06\n",
      "Target 036 has maximum loss 6.36e-05; Target 023 has minimum loss 1.80e-06\n",
      "====================\n",
      "Epoch #83     | Time: 00d 13h 32m  | LR: 2.00e-03  | Epoch time: 594.09  | Train loss: 8.20e-06  | Val loss: 6.35e-06\n",
      "Target 014 has maximum loss 7.08e-05; Target 033 has minimum loss 1.60e-06\n",
      "====================\n",
      "Epoch #84     | Time: 00d 13h 42m  | LR: 2.00e-03  | Epoch time: 593.10  | Train loss: 6.68e-06  | Val loss: 8.74e-06\n",
      "Target 014 has maximum loss 3.93e-05; Target 018 has minimum loss 1.77e-06\n",
      "====================\n",
      "Epoch #85     | Time: 00d 13h 52m  | LR: 2.00e-03  | Epoch time: 593.20  | Train loss: 6.95e-06  | Val loss: 5.76e-06\n",
      "Target 001 has maximum loss 6.26e-05; Target 003 has minimum loss 1.26e-06\n",
      "====================\n",
      "Epoch #86     | Time: 00d 14h 02m  | LR: 2.00e-03  | Epoch time: 582.57  | Train loss: 1.02e-05  | Val loss: 6.82e-06\n",
      "Target 006 has maximum loss 3.19e-05; Target 018 has minimum loss 2.01e-06\n",
      "====================\n",
      "Epoch #87     | Time: 00d 14h 12m  | LR: 2.00e-03  | Epoch time: 580.37  | Train loss: 7.71e-06  | Val loss: 7.19e-06\n",
      "Target 024 has maximum loss 5.45e-05; Target 015 has minimum loss 2.44e-06\n",
      "====================\n",
      "Epoch #88     | Time: 00d 14h 21m  | LR: 2.00e-03  | Epoch time: 581.66  | Train loss: 8.94e-06  | Val loss: 7.12e-06\n",
      "Target 042 has maximum loss 3.80e-05; Target 018 has minimum loss 2.22e-06\n",
      "====================\n",
      "Epoch #89     | Time: 00d 14h 31m  | LR: 2.00e-03  | Epoch time: 576.94  | Train loss: 6.78e-06  | Val loss: 6.20e-06\n",
      "Target 004 has maximum loss 3.61e-05; Target 023 has minimum loss 1.51e-06\n",
      "====================\n",
      "Epoch #90     | Time: 00d 14h 41m  | LR: 2.00e-03  | Epoch time: 580.60  | Train loss: 6.97e-06  | Val loss: 1.18e-05\n",
      "Target 036 has maximum loss 7.75e-05; Target 003 has minimum loss 3.27e-06\n",
      "====================\n",
      "Epoch #91     | Time: 00d 14h 50m  | LR: 2.00e-03  | Epoch time: 581.08  | Train loss: 6.60e-06  | Val loss: 7.36e-06\n",
      "Target 042 has maximum loss 5.39e-05; Target 033 has minimum loss 2.12e-06\n",
      "====================\n",
      "Epoch #92     | Time: 00d 15h 00m  | LR: 2.00e-03  | Epoch time: 579.85  | Train loss: 6.63e-06  | Val loss: 4.68e-06\n",
      "Target 000 has maximum loss 3.20e-05; Target 023 has minimum loss 1.33e-06\n",
      "====================\n",
      "Epoch #93     | Time: 00d 15h 10m  | LR: 2.00e-03  | Epoch time: 579.46  | Train loss: 7.65e-06  | Val loss: 1.03e-05\n",
      "Target 001 has maximum loss 2.34e-04; Target 033 has minimum loss 2.51e-06\n",
      "====================\n",
      "Epoch #94     | Time: 00d 15h 19m  | LR: 2.00e-03  | Epoch time: 577.38  | Train loss: 6.76e-06  | Val loss: 4.01e-06\n",
      "Target 014 has maximum loss 2.13e-05; Target 033 has minimum loss 1.10e-06\n",
      "====================\n",
      "Epoch #95     | Time: 00d 15h 29m  | LR: 2.00e-03  | Epoch time: 575.54  | Train loss: 6.46e-06  | Val loss: 1.21e-05\n",
      "Target 024 has maximum loss 7.46e-05; Target 023 has minimum loss 2.70e-06\n",
      "====================\n",
      "Epoch #96     | Time: 00d 15h 39m  | LR: 2.00e-03  | Epoch time: 576.43  | Train loss: 6.59e-06  | Val loss: 5.88e-06\n",
      "Target 036 has maximum loss 3.82e-05; Target 023 has minimum loss 1.55e-06\n",
      "====================\n",
      "Epoch #97     | Time: 00d 15h 48m  | LR: 2.00e-03  | Epoch time: 579.26  | Train loss: 6.44e-06  | Val loss: 7.84e-06\n",
      "Target 024 has maximum loss 5.26e-05; Target 015 has minimum loss 2.36e-06\n",
      "====================\n",
      "Epoch #98     | Time: 00d 15h 58m  | LR: 2.00e-03  | Epoch time: 578.36  | Train loss: 6.62e-06  | Val loss: 6.74e-06\n",
      "Target 014 has maximum loss 2.85e-05; Target 003 has minimum loss 1.11e-06\n",
      "====================\n",
      "Epoch #99     | Time: 00d 16h 07m  | LR: 2.00e-03  | Epoch time: 573.98  | Train loss: 7.86e-06  | Val loss: 8.66e-06\n",
      "Target 006 has maximum loss 1.27e-04; Target 033 has minimum loss 2.23e-06\n",
      "====================\n",
      "Epoch #100    | Time: 00d 16h 17m  | LR: 2.00e-03  | Epoch time: 575.68  | Train loss: 7.24e-06  | Val loss: 9.23e-06\n",
      "Target 024 has maximum loss 9.75e-05; Target 023 has minimum loss 2.22e-06\n",
      "====================\n",
      "Epoch #101    | Time: 00d 16h 27m  | LR: 2.00e-03  | Epoch time: 575.17  | Train loss: 6.98e-06  | Val loss: 9.29e-06\n",
      "Target 000 has maximum loss 9.20e-05; Target 003 has minimum loss 1.60e-06\n",
      "====================\n",
      "Epoch #102    | Time: 00d 16h 36m  | LR: 2.00e-03  | Epoch time: 574.88  | Train loss: 6.30e-06  | Val loss: 5.94e-06\n",
      "Target 013 has maximum loss 3.57e-05; Target 033 has minimum loss 1.41e-06\n",
      "====================\n",
      "Epoch #103    | Time: 00d 16h 46m  | LR: 2.00e-03  | Epoch time: 575.79  | Train loss: 7.19e-06  | Val loss: 1.19e-05\n",
      "Target 001 has maximum loss 1.27e-04; Target 003 has minimum loss 2.53e-06\n",
      "====================\n",
      "Epoch #104    | Time: 00d 16h 55m  | LR: 2.00e-03  | Epoch time: 575.46  | Train loss: 7.18e-06  | Val loss: 7.09e-06\n",
      "Target 001 has maximum loss 6.22e-05; Target 018 has minimum loss 1.54e-06\n",
      "====================\n",
      "Epoch #105    | Time: 00d 17h 05m  | LR: 2.00e-03  | Epoch time: 574.96  | Train loss: 5.79e-06  | Val loss: 6.48e-06\n",
      "Target 000 has maximum loss 5.94e-05; Target 033 has minimum loss 1.86e-06\n",
      "====================\n",
      "Epoch #106    | Time: 00d 17h 15m  | LR: 2.00e-03  | Epoch time: 575.71  | Train loss: 6.65e-06  | Val loss: 5.44e-06\n",
      "Target 014 has maximum loss 4.30e-05; Target 023 has minimum loss 1.74e-06\n",
      "====================\n",
      "Epoch #107    | Time: 00d 17h 24m  | LR: 2.00e-03  | Epoch time: 575.65  | Train loss: 5.79e-06  | Val loss: 5.43e-06\n",
      "Target 036 has maximum loss 1.99e-05; Target 018 has minimum loss 1.96e-06\n",
      "====================\n",
      "Epoch #108    | Time: 00d 17h 34m  | LR: 2.00e-03  | Epoch time: 576.07  | Train loss: 5.61e-06  | Val loss: 3.92e-06\n",
      "Target 000 has maximum loss 4.46e-05; Target 033 has minimum loss 1.28e-06\n",
      "====================\n",
      "Epoch #109    | Time: 00d 17h 43m  | LR: 2.00e-03  | Epoch time: 576.32  | Train loss: 6.21e-06  | Val loss: 3.99e-06\n",
      "Target 006 has maximum loss 4.21e-05; Target 003 has minimum loss 8.71e-07\n",
      "====================\n",
      "Epoch #110    | Time: 00d 17h 53m  | LR: 2.00e-03  | Epoch time: 575.74  | Train loss: 5.50e-06  | Val loss: 5.53e-06\n",
      "Target 014 has maximum loss 3.97e-05; Target 033 has minimum loss 1.29e-06\n",
      "====================\n",
      "Epoch #111    | Time: 00d 18h 03m  | LR: 2.00e-03  | Epoch time: 575.96  | Train loss: 7.07e-06  | Val loss: 6.16e-06\n",
      "Target 014 has maximum loss 4.97e-05; Target 033 has minimum loss 1.37e-06\n",
      "====================\n",
      "Epoch #112    | Time: 00d 18h 12m  | LR: 2.00e-03  | Epoch time: 574.87  | Train loss: 6.44e-06  | Val loss: 4.39e-06\n",
      "Target 001 has maximum loss 4.84e-05; Target 023 has minimum loss 1.33e-06\n",
      "====================\n",
      "Epoch #113    | Time: 00d 18h 22m  | LR: 2.00e-03  | Epoch time: 574.90  | Train loss: 6.09e-06  | Val loss: 4.39e-06\n",
      "Target 014 has maximum loss 2.39e-05; Target 018 has minimum loss 1.55e-06\n",
      "====================\n",
      "Epoch #114    | Time: 00d 18h 31m  | LR: 2.00e-03  | Epoch time: 574.70  | Train loss: 5.75e-06  | Val loss: 4.20e-06\n",
      "Target 014 has maximum loss 3.98e-05; Target 018 has minimum loss 9.44e-07\n",
      "====================\n",
      "Epoch #115    | Time: 00d 18h 41m  | LR: 2.00e-03  | Epoch time: 574.38  | Train loss: 6.76e-06  | Val loss: 7.40e-06\n",
      "Target 004 has maximum loss 8.40e-05; Target 033 has minimum loss 1.63e-06\n",
      "====================\n",
      "Epoch #116    | Time: 00d 18h 51m  | LR: 2.00e-03  | Epoch time: 574.89  | Train loss: 4.27e-06  | Val loss: 4.25e-06\n",
      "Target 014 has maximum loss 3.98e-05; Target 003 has minimum loss 1.04e-06\n",
      "====================\n",
      "Epoch #117    | Time: 00d 19h 00m  | LR: 2.00e-03  | Epoch time: 575.14  | Train loss: 5.72e-06  | Val loss: 5.58e-06\n",
      "Target 001 has maximum loss 1.19e-04; Target 003 has minimum loss 9.24e-07\n",
      "====================\n",
      "Epoch #118    | Time: 00d 19h 10m  | LR: 2.00e-03  | Epoch time: 575.04  | Train loss: 5.34e-06  | Val loss: 4.51e-06\n",
      "Target 014 has maximum loss 2.62e-05; Target 003 has minimum loss 9.18e-07\n",
      "====================\n",
      "Epoch #119    | Time: 00d 19h 19m  | LR: 2.00e-03  | Epoch time: 573.63  | Train loss: 5.20e-06  | Val loss: 5.93e-06\n",
      "Target 000 has maximum loss 2.30e-05; Target 018 has minimum loss 8.99e-07\n",
      "====================\n",
      "Epoch #120    | Time: 00d 19h 29m  | LR: 2.00e-03  | Epoch time: 574.08  | Train loss: 5.10e-06  | Val loss: 4.93e-06\n",
      "Target 001 has maximum loss 6.01e-05; Target 003 has minimum loss 1.50e-06\n",
      "====================\n",
      "Epoch #121    | Time: 00d 19h 39m  | LR: 2.00e-03  | Epoch time: 575.46  | Train loss: 6.67e-06  | Val loss: 3.40e-06\n",
      "Target 014 has maximum loss 2.26e-05; Target 018 has minimum loss 9.33e-07\n",
      "====================\n",
      "Epoch #122    | Time: 00d 19h 48m  | LR: 2.00e-03  | Epoch time: 579.15  | Train loss: 5.65e-06  | Val loss: 6.66e-06\n",
      "Target 001 has maximum loss 7.96e-05; Target 003 has minimum loss 8.60e-07\n",
      "====================\n",
      "Epoch #123    | Time: 00d 19h 58m  | LR: 2.00e-03  | Epoch time: 580.32  | Train loss: 6.89e-06  | Val loss: 8.48e-06\n",
      "Target 006 has maximum loss 7.19e-05; Target 003 has minimum loss 2.10e-06\n",
      "====================\n",
      "Epoch #124    | Time: 00d 20h 08m  | LR: 2.00e-03  | Epoch time: 580.98  | Train loss: 4.89e-06  | Val loss: 3.43e-06\n",
      "Target 000 has maximum loss 1.67e-05; Target 003 has minimum loss 8.90e-07\n",
      "====================\n",
      "Epoch #125    | Time: 00d 20h 17m  | LR: 2.00e-03  | Epoch time: 580.25  | Train loss: 4.96e-06  | Val loss: 4.60e-06\n",
      "Target 007 has maximum loss 1.92e-05; Target 033 has minimum loss 1.15e-06\n",
      "====================\n",
      "Epoch #126    | Time: 00d 20h 27m  | LR: 2.00e-03  | Epoch time: 579.33  | Train loss: 5.22e-06  | Val loss: 3.65e-06\n",
      "Target 042 has maximum loss 2.61e-05; Target 003 has minimum loss 1.04e-06\n",
      "====================\n",
      "Epoch #127    | Time: 00d 20h 37m  | LR: 2.00e-03  | Epoch time: 580.07  | Train loss: 5.05e-06  | Val loss: 3.30e-06\n",
      "Target 001 has maximum loss 2.81e-05; Target 003 has minimum loss 7.37e-07\n",
      "====================\n",
      "Epoch #128    | Time: 00d 20h 46m  | LR: 2.00e-03  | Epoch time: 579.95  | Train loss: 5.05e-06  | Val loss: 7.86e-06\n",
      "Target 042 has maximum loss 3.06e-05; Target 003 has minimum loss 1.31e-06\n",
      "====================\n",
      "Epoch #129    | Time: 00d 20h 56m  | LR: 2.00e-03  | Epoch time: 580.73  | Train loss: 5.40e-06  | Val loss: 4.89e-06\n",
      "Target 002 has maximum loss 3.09e-05; Target 020 has minimum loss 1.50e-06\n",
      "====================\n",
      "Epoch #130    | Time: 00d 21h 06m  | LR: 2.00e-03  | Epoch time: 580.11  | Train loss: 4.43e-06  | Val loss: 9.47e-06\n",
      "Target 004 has maximum loss 7.98e-05; Target 033 has minimum loss 2.33e-06\n",
      "====================\n",
      "Epoch #131    | Time: 00d 21h 15m  | LR: 2.00e-03  | Epoch time: 579.86  | Train loss: 4.88e-06  | Val loss: 1.06e-05\n",
      "Target 004 has maximum loss 2.10e-04; Target 023 has minimum loss 1.89e-06\n",
      "====================\n",
      "Epoch #132    | Time: 00d 21h 25m  | LR: 2.00e-03  | Epoch time: 579.49  | Train loss: 4.89e-06  | Val loss: 3.99e-06\n",
      "Target 036 has maximum loss 2.42e-05; Target 023 has minimum loss 9.76e-07\n",
      "====================\n",
      "Epoch #133    | Time: 00d 21h 35m  | LR: 2.00e-03  | Epoch time: 580.45  | Train loss: 4.86e-06  | Val loss: 7.11e-06\n",
      "Target 036 has maximum loss 2.08e-05; Target 003 has minimum loss 1.43e-06\n",
      "====================\n",
      "Epoch #134    | Time: 00d 21h 44m  | LR: 2.00e-03  | Epoch time: 580.34  | Train loss: 4.94e-06  | Val loss: 2.83e-06\n",
      "Target 036 has maximum loss 1.53e-05; Target 003 has minimum loss 7.20e-07\n",
      "====================\n",
      "Epoch #135    | Time: 00d 21h 54m  | LR: 2.00e-03  | Epoch time: 579.90  | Train loss: 4.61e-06  | Val loss: 4.18e-06\n",
      "Target 000 has maximum loss 6.07e-05; Target 018 has minimum loss 9.56e-07\n",
      "====================\n",
      "Epoch #136    | Time: 00d 22h 04m  | LR: 2.00e-03  | Epoch time: 580.24  | Train loss: 5.72e-06  | Val loss: 6.44e-06\n",
      "Target 001 has maximum loss 8.35e-05; Target 023 has minimum loss 1.73e-06\n",
      "====================\n",
      "Epoch #137    | Time: 00d 22h 13m  | LR: 2.00e-03  | Epoch time: 580.87  | Train loss: 6.01e-06  | Val loss: 5.04e-06\n",
      "Target 000 has maximum loss 3.67e-05; Target 003 has minimum loss 1.37e-06\n",
      "====================\n",
      "Epoch #138    | Time: 00d 22h 23m  | LR: 2.00e-03  | Epoch time: 580.14  | Train loss: 5.16e-05  | Val loss: 4.98e-06\n",
      "Target 014 has maximum loss 2.16e-05; Target 033 has minimum loss 1.63e-06\n",
      "====================\n",
      "Epoch #139    | Time: 00d 22h 33m  | LR: 2.00e-03  | Epoch time: 580.42  | Train loss: 4.83e-06  | Val loss: 3.56e-06\n",
      "Target 014 has maximum loss 2.53e-05; Target 003 has minimum loss 1.07e-06\n",
      "====================\n",
      "Epoch #140    | Time: 00d 22h 42m  | LR: 2.00e-03  | Epoch time: 580.01  | Train loss: 4.54e-06  | Val loss: 2.94e-06\n",
      "Target 014 has maximum loss 1.22e-05; Target 003 has minimum loss 8.88e-07\n",
      "====================\n",
      "Epoch #141    | Time: 00d 22h 52m  | LR: 2.00e-03  | Epoch time: 580.12  | Train loss: 4.32e-06  | Val loss: 8.11e-06\n",
      "Target 024 has maximum loss 3.69e-05; Target 023 has minimum loss 2.56e-06\n",
      "====================\n",
      "Epoch #142    | Time: 00d 23h 02m  | LR: 2.00e-03  | Epoch time: 580.50  | Train loss: 4.98e-06  | Val loss: 3.88e-06\n",
      "Target 024 has maximum loss 2.67e-05; Target 023 has minimum loss 1.08e-06\n",
      "====================\n",
      "Epoch #143    | Time: 00d 23h 11m  | LR: 2.00e-03  | Epoch time: 579.85  | Train loss: 5.74e-06  | Val loss: 3.51e-06\n",
      "Target 001 has maximum loss 3.29e-05; Target 003 has minimum loss 8.02e-07\n",
      "====================\n",
      "Epoch #144    | Time: 00d 23h 21m  | LR: 2.00e-03  | Epoch time: 581.24  | Train loss: 4.97e-06  | Val loss: 1.01e-05\n",
      "Target 036 has maximum loss 9.59e-05; Target 033 has minimum loss 1.67e-06\n",
      "====================\n",
      "Epoch #145    | Time: 00d 23h 31m  | LR: 2.00e-03  | Epoch time: 580.05  | Train loss: 4.64e-06  | Val loss: 1.14e-05\n",
      "Target 004 has maximum loss 7.27e-05; Target 020 has minimum loss 3.43e-06\n",
      "====================\n",
      "Epoch #146    | Time: 00d 23h 41m  | LR: 2.00e-03  | Epoch time: 579.85  | Train loss: 4.76e-06  | Val loss: 4.90e-06\n",
      "Target 014 has maximum loss 4.76e-05; Target 003 has minimum loss 1.12e-06\n",
      "====================\n",
      "Epoch #147    | Time: 00d 23h 50m  | LR: 2.00e-03  | Epoch time: 581.32  | Train loss: 4.55e-06  | Val loss: 3.94e-06\n",
      "Target 036 has maximum loss 3.33e-05; Target 033 has minimum loss 9.54e-07\n",
      "====================\n",
      "Epoch #148    | Time: 01d 00h 00m  | LR: 2.00e-03  | Epoch time: 579.87  | Train loss: 5.43e-06  | Val loss: 6.98e-06\n",
      "Target 024 has maximum loss 3.75e-05; Target 005 has minimum loss 1.43e-06\n",
      "====================\n",
      "Epoch #149    | Time: 01d 00h 10m  | LR: 2.00e-03  | Epoch time: 580.65  | Train loss: 4.41e-06  | Val loss: 3.24e-06\n",
      "Target 001 has maximum loss 4.04e-05; Target 003 has minimum loss 8.70e-07\n",
      "====================\n",
      "Epoch #150    | Time: 01d 00h 19m  | LR: 2.00e-03  | Epoch time: 577.32  | Train loss: 4.34e-06  | Val loss: 3.23e-06\n",
      "Target 001 has maximum loss 2.28e-05; Target 018 has minimum loss 7.25e-07\n",
      "====================\n",
      "Epoch #151    | Time: 01d 00h 29m  | LR: 2.00e-03  | Epoch time: 574.87  | Train loss: 4.70e-06  | Val loss: 3.76e-06\n",
      "Target 042 has maximum loss 2.18e-05; Target 033 has minimum loss 9.55e-07\n",
      "====================\n",
      "Epoch #152    | Time: 01d 00h 38m  | LR: 2.00e-03  | Epoch time: 574.95  | Train loss: 4.56e-06  | Val loss: 4.75e-06\n",
      "Target 024 has maximum loss 4.42e-05; Target 005 has minimum loss 1.91e-06\n",
      "====================\n",
      "Epoch #153    | Time: 01d 00h 48m  | LR: 2.00e-03  | Epoch time: 574.58  | Train loss: 5.59e-06  | Val loss: 8.49e-06\n",
      "Target 001 has maximum loss 1.88e-04; Target 005 has minimum loss 2.28e-06\n",
      "====================\n",
      "Epoch #154    | Time: 01d 00h 58m  | LR: 2.00e-03  | Epoch time: 577.34  | Train loss: 6.05e-06  | Val loss: 4.35e-06\n",
      "Target 012 has maximum loss 4.71e-05; Target 018 has minimum loss 9.80e-07\n",
      "====================\n",
      "Epoch #155    | Time: 01d 01h 07m  | LR: 2.00e-03  | Epoch time: 580.76  | Train loss: 4.75e-06  | Val loss: 4.20e-06\n",
      "Target 001 has maximum loss 2.03e-05; Target 003 has minimum loss 9.06e-07\n",
      "====================\n",
      "Epoch #156    | Time: 01d 01h 17m  | LR: 2.00e-03  | Epoch time: 575.65  | Train loss: 4.46e-06  | Val loss: 3.06e-06\n",
      "Target 006 has maximum loss 2.85e-05; Target 023 has minimum loss 9.83e-07\n",
      "====================\n",
      "Epoch #157    | Time: 01d 01h 27m  | LR: 2.00e-03  | Epoch time: 577.06  | Train loss: 4.27e-06  | Val loss: 3.00e-06\n",
      "Target 024 has maximum loss 1.72e-05; Target 030 has minimum loss 1.12e-06\n",
      "====================\n",
      "Epoch #158    | Time: 01d 01h 36m  | LR: 2.00e-03  | Epoch time: 580.24  | Train loss: 4.45e-06  | Val loss: 5.23e-06\n",
      "Target 024 has maximum loss 4.62e-05; Target 033 has minimum loss 1.51e-06\n",
      "====================\n",
      "Epoch #159    | Time: 01d 01h 46m  | LR: 2.00e-03  | Epoch time: 579.85  | Train loss: 4.09e-06  | Val loss: 2.93e-06\n",
      "Target 014 has maximum loss 9.77e-06; Target 003 has minimum loss 6.30e-07\n",
      "====================\n",
      "Epoch #160    | Time: 01d 01h 56m  | LR: 2.00e-03  | Epoch time: 580.35  | Train loss: 4.25e-06  | Val loss: 3.46e-06\n",
      "Target 014 has maximum loss 1.01e-05; Target 003 has minimum loss 8.66e-07\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msubprocess\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m sp\u001b[38;5;241m.\u001b[39mrun([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxDeepH/xdeeph-train.py\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCrI3_monolayer.ini\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-n\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m6\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/subprocess.py:550\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[1;32m    548\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 550\u001b[0m         stdout, stderr \u001b[38;5;241m=\u001b[39m process\u001b[38;5;241m.\u001b[39mcommunicate(\u001b[38;5;28minput\u001b[39m, timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    552\u001b[0m         process\u001b[38;5;241m.\u001b[39mkill()\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/subprocess.py:1201\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1199\u001b[0m         stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1200\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m-> 1201\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait()\n\u001b[1;32m   1202\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/subprocess.py:1264\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1262\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m _time() \u001b[38;5;241m+\u001b[39m timeout\n\u001b[1;32m   1263\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wait(timeout\u001b[38;5;241m=\u001b[39mtimeout)\n\u001b[1;32m   1265\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1266\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[1;32m   1268\u001b[0m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[1;32m   1269\u001b[0m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/subprocess.py:2053\u001b[0m, in \u001b[0;36mPopen._wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   2051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2052\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# Another thread waited.\u001b[39;00m\n\u001b[0;32m-> 2053\u001b[0m (pid, sts) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_wait(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m   2054\u001b[0m \u001b[38;5;66;03m# Check the pid and loop as waitpid has been known to\u001b[39;00m\n\u001b[1;32m   2055\u001b[0m \u001b[38;5;66;03m# return 0 even without WNOHANG in odd situations.\u001b[39;00m\n\u001b[1;32m   2056\u001b[0m \u001b[38;5;66;03m# http://bugs.python.org/issue14396.\u001b[39;00m\n\u001b[1;32m   2057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pid \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/subprocess.py:2011\u001b[0m, in \u001b[0;36mPopen._try_wait\u001b[0;34m(self, wait_flags)\u001b[0m\n\u001b[1;32m   2009\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"All callers to this function MUST hold self._waitpid_lock.\"\"\"\u001b[39;00m\n\u001b[1;32m   2010\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2011\u001b[0m     (pid, sts) \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mwaitpid(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid, wait_flags)\n\u001b[1;32m   2012\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mChildProcessError\u001b[39;00m:\n\u001b[1;32m   2013\u001b[0m     \u001b[38;5;66;03m# This happens if SIGCLD is set to be ignored or waiting\u001b[39;00m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;66;03m# for child processes has otherwise been disabled for our\u001b[39;00m\n\u001b[1;32m   2015\u001b[0m     \u001b[38;5;66;03m# process.  This child is dead, we can't get the status.\u001b[39;00m\n\u001b[1;32m   2016\u001b[0m     pid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpid\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import subprocess as sp\n",
    "\n",
    "sp.run(['python', 'xDeepH/xdeeph-train.py', 'CrI3_monolayer.ini', '-n', '6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f840786a-71aa-4377-8eb0-c8824fa279f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-n N] CONFIG\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3561: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# ========================= #\n",
    "# Training of network model #\n",
    "# ========================= #\n",
    "\n",
    "# Usage: python <path-to-this-file>/train.py <your_config>.ini [-n NUM_THREADS]\n",
    "# Default train config file is xdeeph/default_configs/train_default.ini\n",
    "\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Train xDeepH network')\n",
    "parser.add_argument('config', type=str, metavar='CONFIG', help='Config file for training')\n",
    "parser.add_argument('-n', type=int, default=None, help='Maximum number of threads')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if args.n is not None:\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = f\"{args.n}\"\n",
    "    os.environ[\"MKL_NUM_THREADS\"] = f\"{args.n}\"\n",
    "    os.environ[\"NUMEXPR_NUM_THREADS\"] = f\"{args.n}\"\n",
    "    os.environ[\"OPENBLAS_NUM_THREADS\"] = f\"{args.n}\"\n",
    "    os.environ[\"VECLIB_MAXIMUM_THREADS\"] = f\"{args.n}\"\n",
    "    import torch\n",
    "    torch.set_num_threads(args.n)\n",
    "\n",
    "from xdeeph import xDeepHKernel\n",
    "kernel = xDeepHKernel()\n",
    "kernel.train(args.config)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
